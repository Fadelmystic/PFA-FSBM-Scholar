#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script de TÃ©lÃ©chargement - ModÃ¨le FSBM LLaMA Fine-tunÃ©
=======================================================

Ce script vÃ©rifie et prÃ©pare le tÃ©lÃ©chargement du modÃ¨le fine-tunÃ© depuis Kaggle.
"""

import os
import sys
import json
import zipfile
from pathlib import Path

def print_header():
    """Afficher l'en-tÃªte du script"""
    print("=" * 60)
    print("ğŸ“¥ SCRIPT DE TÃ‰LÃ‰CHARGEMENT - FSBM LLaMA FINE-TUNÃ‰")
    print("=" * 60)
    print()

def check_model_files():
    """VÃ©rifier que tous les fichiers du modÃ¨le sont prÃ©sents"""
    print("ğŸ” VÃ‰RIFICATION DES FICHIERS DU MODÃˆLE...")
    
    model_dir = "fsbm-llama-working"
    zip_file = "fsbm-llama-finetuned-model.zip"
    
    # VÃ©rifier le dossier principal
    if not os.path.exists(model_dir):
        print(f"âŒ Dossier modÃ¨le non trouvÃ©: {model_dir}")
        return False
    
    print(f"âœ… Dossier modÃ¨le trouvÃ©: {model_dir}")
    
    # VÃ©rifier les fichiers essentiels
    essential_files = [
        "adapter_model.bin",
        "adapter_config.json", 
        "tokenizer.json",
        "tokenizer_config.json",
        "special_tokens_map.json",
        "chat_template.jinja",
        "README.md",
        "model_info.json"
    ]
    
    missing_files = []
    for file in essential_files:
        file_path = os.path.join(model_dir, file)
        if os.path.exists(file_path):
            size = os.path.getsize(file_path) / (1024 * 1024)  # MB
            print(f"âœ… {file} ({size:.1f} MB)")
        else:
            print(f"âŒ {file} - MANQUANT")
            missing_files.append(file)
    
    # VÃ©rifier les checkpoints
    checkpoint_dirs = [d for d in os.listdir(model_dir) if d.startswith("checkpoint-")]
    if checkpoint_dirs:
        print(f"âœ… Checkpoints trouvÃ©s: {len(checkpoint_dirs)}")
        for checkpoint in checkpoint_dirs:
            print(f"  ğŸ“ {checkpoint}/")
    else:
        print("âš ï¸ Aucun checkpoint trouvÃ©")
    
    # VÃ©rifier le fichier ZIP
    if os.path.exists(zip_file):
        zip_size = os.path.getsize(zip_file) / (1024 * 1024)  # MB
        print(f"âœ… Fichier ZIP trouvÃ©: {zip_file} ({zip_size:.1f} MB)")
    else:
        print(f"âŒ Fichier ZIP non trouvÃ©: {zip_file}")
        missing_files.append(zip_file)
    
    if missing_files:
        print(f"\nâš ï¸ FICHIERS MANQUANTS: {len(missing_files)}")
        for file in missing_files:
            print(f"  - {file}")
        return False
    
    print("\nâœ… TOUS LES FICHIERS SONT PRÃ‰SENTS!")
    return True

def display_model_info():
    """Afficher les informations du modÃ¨le"""
    print("\nğŸ“Š INFORMATIONS DU MODÃˆLE...")
    
    model_info_path = "fsbm-llama-working/model_info.json"
    if os.path.exists(model_info_path):
        try:
            with open(model_info_path, 'r', encoding='utf-8') as f:
                model_info = json.load(f)
            
            print(f"ğŸ¯ Nom: {model_info.get('model_name', 'N/A')}")
            print(f"ğŸ”§ ModÃ¨le de base: {model_info.get('base_model', 'N/A')}")
            print(f"ğŸ“ˆ Ã‰poques: {model_info.get('training_config', {}).get('epochs', 'N/A')}")
            print(f"ğŸ“š Dataset: {model_info.get('dataset', 'N/A')}")
            print(f"â±ï¸ Temps d'entraÃ®nement: {model_info.get('training_time_seconds', 0):.1f}s")
            print(f"ğŸ’¾ Quantization: {model_info.get('quantization', 'N/A')}")
            print(f"ğŸ”§ Framework: {model_info.get('framework', 'N/A')}")
            
        except Exception as e:
            print(f"âŒ Erreur lecture model_info.json: {e}")
    else:
        print("âŒ Fichier model_info.json non trouvÃ©")

def show_download_instructions():
    """Afficher les instructions de tÃ©lÃ©chargement"""
    print("\nğŸš€ INSTRUCTIONS DE TÃ‰LÃ‰CHARGEMENT...")
    print("=" * 50)
    
    print("\nğŸ“‹ MÃ‰THODE 1: Bouton Download Kaggle (RecommandÃ©e)")
    print("1. Dans Kaggle, allez dans la section 'Output'")
    print("2. Trouvez le fichier: fsbm-llama-finetuned-model.zip")
    print("3. Cliquez sur le bouton 'Download'")
    print("4. Le tÃ©lÃ©chargement commence automatiquement")
    
    print("\nğŸ“‹ MÃ‰THODE 2: Script Bash")
    print("ExÃ©cutez dans une cellule Kaggle:")
    print("!bash download_model.sh")
    
    print("\nğŸ“‹ MÃ‰THODE 3: VÃ©rification Python")
    print("ExÃ©cutez ce script pour vÃ©rifier les fichiers:")
    print("python download_model.py")

def show_usage_instructions():
    """Afficher les instructions d'utilisation"""
    print("\nğŸ’» INSTRUCTIONS D'UTILISATION...")
    print("=" * 50)
    
    print("\n1ï¸âƒ£ Installation des dÃ©pendances:")
    print("pip install transformers peft torch bitsandbytes")
    
    print("\n2ï¸âƒ£ Code d'utilisation:")
    print("""
from transformers import AutoTokenizer, AutoModelForCausalLM
import torch

# Charger le modÃ¨le
tokenizer = AutoTokenizer.from_pretrained("fsbm-llama-working")
model = AutoModelForCausalLM.from_pretrained(
    "fsbm-llama-working",
    device_map="auto",
    trust_remote_code=True
)

# GÃ©nÃ©rer une rÃ©ponse
def generate_response(prompt):
    formatted_prompt = f"<s>[INST] {prompt} [/INST]"
    inputs = tokenizer.encode(formatted_prompt, return_tensors="pt")
    
    with torch.no_grad():
        outputs = model.generate(
            inputs,
            max_new_tokens=100,
            do_sample=True,
            temperature=0.7,
            top_p=0.9,
            repetition_penalty=1.1
        )
    
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    if "[/INST]" in response:
        response = response.split("[/INST]")[1].strip()
    return response

# Test
question = "Qu'est-ce que le Big Data?"
response = generate_response(question)
print(f"RÃ©ponse: {response}")
""")

def show_file_structure():
    """Afficher la structure des fichiers"""
    print("\nğŸ“ STRUCTURE DES FICHIERS...")
    print("=" * 50)
    
    model_dir = "fsbm-llama-working"
    if os.path.exists(model_dir):
        print(f"ğŸ“‚ {model_dir}/")
        for root, dirs, files in os.walk(model_dir):
            level = root.replace(model_dir, '').count(os.sep)
            indent = '  ' * level
            if level > 0:
                print(f"{indent}ğŸ“ {os.path.basename(root)}/")
            for file in files:
                file_path = os.path.join(root, file)
                size = os.path.getsize(file_path) / 1024  # KB
                print(f"{indent}  ğŸ“„ {file} ({size:.1f} KB)")
    else:
        print("âŒ Dossier modÃ¨le non trouvÃ©")

def main():
    """Fonction principale"""
    print_header()
    
    # VÃ©rifier les fichiers
    files_ok = check_model_files()
    
    if files_ok:
        # Afficher les informations
        display_model_info()
        show_file_structure()
        show_download_instructions()
        show_usage_instructions()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ MODÃˆLE PRÃŠT POUR TÃ‰LÃ‰CHARGEMENT!")
        print("=" * 60)
        print("âœ… Tous les fichiers sont prÃ©sents")
        print("âœ… Le modÃ¨le a Ã©tÃ© testÃ© avec succÃ¨s")
        print("âœ… Documentation complÃ¨te incluse")
        print("âœ… Instructions d'utilisation fournies")
        print("\nğŸš€ Vous pouvez maintenant tÃ©lÃ©charger le modÃ¨le!")
        
    else:
        print("\n" + "=" * 60)
        print("âŒ PROBLÃˆME DÃ‰TECTÃ‰!")
        print("=" * 60)
        print("âš ï¸ Certains fichiers sont manquants")
        print("ğŸ”§ VÃ©rifiez que l'entraÃ®nement s'est terminÃ© correctement")
        print("ğŸ”„ Relancez le script d'entraÃ®nement si nÃ©cessaire")
        sys.exit(1)

if __name__ == "__main__":
    main()
