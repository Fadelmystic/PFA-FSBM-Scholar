#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Test Simple - ModÃ¨le FSBM LLaMA Fine-tunÃ©
==========================================

Test simple du tokenizer et vÃ©rification des fichiers.
"""

import os
import json

# Configuration
MODEL_PATH = "Model"

def test_files():
    """Tester la prÃ©sence des fichiers"""
    print("ğŸ” VÃ‰RIFICATION DES FICHIERS...")
    print("=" * 50)
    
    essential_files = [
        "adapter_model.bin",
        "adapter_config.json",
        "tokenizer.json",
        "tokenizer_config.json",
        "special_tokens_map.json",
        "chat_template.jinja",
        "README.md",
        "model_info.json",
        "training_args.bin",
        "tokenizer.model"
    ]
    
    all_files_present = True
    for file in essential_files:
        file_path = os.path.join(MODEL_PATH, file)
        if os.path.exists(file_path):
            size = os.path.getsize(file_path) / (1024 * 1024)  # MB
            print(f"âœ… {file} ({size:.1f} MB)")
        else:
            print(f"âŒ {file} - MANQUANT")
            all_files_present = False
    
    return all_files_present

def test_tokenizer():
    """Tester le tokenizer"""
    print("\nğŸ“ TEST DU TOKENIZER...")
    print("=" * 50)
    
    try:
        from transformers import AutoTokenizer
        
        print("ğŸ”§ Chargement du tokenizer...")
        tokenizer = AutoTokenizer.from_pretrained(
            MODEL_PATH,
            trust_remote_code=True
        )
        
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token
        
        print("âœ… Tokenizer chargÃ©!")
        
        # Test de tokenization
        test_text = "Qu'est-ce que le Big Data?"
        formatted_prompt = f"<s>[INST] {test_text} [/INST]"
        
        print(f"ğŸ“ Test de tokenization: '{test_text}'")
        tokens = tokenizer.encode(formatted_prompt, return_tensors="pt")
        print(f"âœ… Tokens gÃ©nÃ©rÃ©s: {tokens.shape}")
        
        # Test de dÃ©codage
        decoded = tokenizer.decode(tokens[0], skip_special_tokens=True)
        print(f"âœ… DÃ©codage rÃ©ussi: '{decoded}'")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erreur tokenizer: {e}")
        return False

def show_model_info():
    """Afficher les informations du modÃ¨le"""
    print("\nğŸ“Š INFORMATIONS DU MODÃˆLE...")
    print("=" * 50)
    
    model_info_path = os.path.join(MODEL_PATH, "model_info.json")
    if os.path.exists(model_info_path):
        try:
            with open(model_info_path, 'r', encoding='utf-8') as f:
                model_info = json.load(f)
            
            print(f"ğŸ¯ Nom: {model_info.get('model_name', 'N/A')}")
            print(f"ğŸ”§ ModÃ¨le de base: {model_info.get('base_model', 'N/A')}")
            print(f"ğŸ“ˆ Ã‰poques: {model_info.get('training_config', {}).get('epochs', 'N/A')}")
            print(f"ğŸ“š Dataset: {model_info.get('dataset', 'N/A')}")
            print(f"â±ï¸ Temps d'entraÃ®nement: {model_info.get('training_time_seconds', 0):.1f}s")
            print(f"ğŸ’¾ Quantization: {model_info.get('quantization', 'N/A')}")
            print(f"ğŸ”§ Framework: {model_info.get('framework', 'N/A')}")
            
        except Exception as e:
            print(f"âŒ Erreur lecture model_info.json: {e}")
    else:
        print("âŒ Fichier model_info.json non trouvÃ©")

def main():
    """Fonction principale"""
    print("ğŸš€ TEST SIMPLE - MODÃˆLE FSBM LLaMA")
    print("=" * 60)
    
    # Test des fichiers
    files_ok = test_files()
    
    if not files_ok:
        print("\nâŒ FICHIERS MANQUANTS!")
        print("ğŸ’¡ VÃ©rifiez que le modÃ¨le est correctement tÃ©lÃ©chargÃ©")
        return
    
    # Test du tokenizer
    tokenizer_ok = test_tokenizer()
    
    # Afficher les informations
    show_model_info()
    
    print("\n" + "=" * 60)
    if files_ok and tokenizer_ok:
        print("ğŸ‰ TEST RÃ‰USSI!")
        print("âœ… Tous les fichiers sont prÃ©sents")
        print("âœ… Le tokenizer fonctionne")
        print("ğŸ’¡ Le modÃ¨le est prÃªt pour utilisation")
        print("\nğŸ’¡ Prochaines Ã©tapes:")
        print("1. python quick_test_cpu.py - Test rapide sur CPU")
        print("2. python interactive_chat_cpu.py - Chat interactif sur CPU")
    else:
        print("âŒ PROBLÃˆMES DÃ‰TECTÃ‰S!")
        print("ğŸ’¡ VÃ©rifiez les erreurs ci-dessus")

if __name__ == "__main__":
    main()
